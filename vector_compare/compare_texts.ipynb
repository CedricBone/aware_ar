{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification with Embeddings\n",
    "\n",
    "Documentation: https://sbert.net/index.html\n",
    "\n",
    "- lDA/ topic modeling/clustering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sentence_transformers import SentenceTransformer, util, CrossEncoder\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoModel\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import json\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence transformer comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\"Romance\",\"Science Fiction\",\"Dystopian\",\"Thriller\",\"Historical Fiction\",\"Drama\",\"Mystery\",\"Fantasy\"]\n",
    "\n",
    "models = [\n",
    "    \"all-mpnet-base-v2\",\n",
    "    \"gtr-t5-xxl\",\n",
    "    \"gtr-t5-xl\",\n",
    "    \"sentence-t5-xxl\",\n",
    "    \"gtr-t5-large\",\n",
    "    \"all-mpnet-base-v1\",\n",
    "    \"multi-qa-mpnet-base-dot-v1\",\n",
    "    \"multi-qa-mpnet-base-cos-v1\",\n",
    "    \"all-roberta-large-v1\",\n",
    "    \"sentence-t5-xl\",\n",
    "    \"all-distilroberta-v1\",\n",
    "    \"all-MiniLM-L12-v1\",\n",
    "    \"all-MiniLM-L12-v2\",\n",
    "    \"multi-qa-distilbert-dot-v1\",\n",
    "    \"multi-qa-distilbert-cos-v1\",\n",
    "    \"gtr-t5-base\",\n",
    "    \"sentence-t5-large\",\n",
    "    \"all-MiniLM-L6-v2\",\n",
    "    \"multi-qa-MiniLM-L6-cos-v1\",\n",
    "    \"all-MiniLM-L6-v1\",\n",
    "    \"paraphrase-mpnet-base-v2\",\n",
    "    \"msmarco-bert-base-dot-v5\",\n",
    "    \"multi-qa-MiniLM-L6-dot-v1\",\n",
    "    \"sentence-t5-base\",\n",
    "    \"msmarco-distilbert-base-tas-b\",\n",
    "    \"msmarco-distilbert-dot-v5\",\n",
    "    \"paraphrase-distilroberta-base-v2\",\n",
    "    \"paraphrase-MiniLM-L12-v2\",\n",
    "    \"paraphrase-multilingual-mpnet-base-v2\",\n",
    "    \"paraphrase-TinyBERT-L6-v2\",\n",
    "    \"paraphrase-MiniLM-L6-v2\",\n",
    "    \"paraphrase-albert-small-v2\",\n",
    "    \"paraphrase-multilingual-MiniLM-L12-v2\",\n",
    "    \"paraphrase-MiniLM-L3-v2\",\n",
    "    \"distiluse-base-multilingual-cased-v1\",\n",
    "    \"distiluse-base-multilingual-cased-v2\",\n",
    "    \"average_word_embeddings_komninos\",\n",
    "    \"average_word_embeddings_glove.6B.300d\"\n",
    "]\n",
    "\n",
    "\n",
    "model = SentenceTransformer(models[0])\n",
    "category_embeddings = model.encode(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_sim_pairs(categories, similarities):\n",
    "    output = []\n",
    "    for index in range(len(categories)):\n",
    "        output.append( (categories[index], similarities[index]) )\n",
    "\n",
    "    output = sorted(output, key=lambda x: x[1], reverse=True)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('books.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "for entry in data:\n",
    "    description = entry[\"description\"]\n",
    "    title = entry[\"title\"]\n",
    "\n",
    "    # description -> vector\n",
    "    description_embedding = model.encode(description)\n",
    "\n",
    "    # cosine sim (description, category)\n",
    "    similarities = util.cos_sim(description_embedding, category_embeddings)[0].tolist()\n",
    "    pairs = category_sim_pairs(categories, similarities)\n",
    "\n",
    "    print(f\"Title: {title}:\")\n",
    "    #print(f\"  Description: {description}\")\n",
    "    print(f\"Categories:\")\n",
    "    for category, similarity in pairs:\n",
    "        print(f\"{category}: {similarity:.4f}\")\n",
    "    print(\"#\"*30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence transformer comparison with more descriptive categories and descriptions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\n",
    "    \"This book is a romance novel about love and relationships.\",\n",
    "    \"This book is a science fiction novel about futuristic concepts and technology.\",\n",
    "    \"This book is a dystopian story set in a bleak or controlled society.\",\n",
    "    \"This book is a thriller that is suspenseful and full of tension.\",\n",
    "    \"This book is a historical fiction novel set in a past time period.\",\n",
    "    \"This book is a drama focusing on serious and emotional storytelling.\",\n",
    "    \"This book is a mystery novel involving investigation and secrets.\",\n",
    "    \"This book is a fantasy novel featuring magic, mythical creatures, or supernatural elements.\"\n",
    "]\n",
    "\n",
    "category_embeddings = model.encode(categories)\n",
    "\n",
    "\n",
    "with open('books.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "for entry in data:\n",
    "    title = entry[\"title\"]\n",
    "    description = entry[\"description\"]\n",
    "\n",
    "    formatted_description = f\"This book is about: {description} The genre of this book is:\"\n",
    "    description_embedding = model.encode(formatted_description)\n",
    "\n",
    "    similarities = util.cos_sim(description_embedding, category_embeddings)[0].tolist()\n",
    "    pairs = category_sim_pairs(categories, similarities)\n",
    "\n",
    "    print(f\"Title: {title}\")\n",
    "    #print(f\" Description: {description}\")\n",
    "    print(f\"Categories:\")\n",
    "    for category, similarity in pairs:\n",
    "        print(f\"{category}: {similarity:.4f}\")\n",
    "    print(\"#\"*30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Encoder Comparison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")\n",
    "\n",
    "with open('books.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "for entry in data:\n",
    "    description = entry[\"description\"]\n",
    "    title = entry[\"title\"]\n",
    "\n",
    "    pairs = [(description, category) for category in categories]\n",
    "    #similarity scores\n",
    "    scores = model.predict(pairs)  \n",
    "\n",
    "    ranked_categories = category_sim_pairs(categories, scores)\n",
    "\n",
    "    print(f\"Title: {title}\")\n",
    "    print(\"Categories:\")\n",
    "    for category, score in ranked_categories:\n",
    "        print(f\"{category}: {score:.4f}\")\n",
    "    print(\"#\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLIP image comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\"clip-ViT-B-32\")\n",
    "\n",
    "image_folder = \"images/\"\n",
    "\n",
    "# Load image filenames \n",
    "image_files = []\n",
    "for file in os.listdir(image_folder):\n",
    "    if file.endswith((\"jpg\", \"jpeg\", \"png\")):\n",
    "        image_files.append(file)\n",
    "\n",
    "image_embeddings = {}\n",
    "for img_file in image_files:\n",
    "    img_path = os.path.join(image_folder, img_file)\n",
    "    img_emb = model.encode(Image.open(img_path))\n",
    "    image_embeddings[img_file] = img_emb\n",
    "\n",
    "def rank_images(description, image_embeddings):\n",
    "    text_emb = model.encode([description]) \n",
    "    # similarity scores\n",
    "    scores = {img: model.similarity(text_emb, img_emb)[0][0] for img, img_emb in image_embeddings.items()}\n",
    "\n",
    "    sorted_scores = []\n",
    "    for key, value in scores.items():\n",
    "        sorted_scores.append((key, value))\n",
    "    sorted_scores = sorted(sorted_scores, key=lambda x: x[1], reverse=True)\n",
    "    return tuple(sorted_scores)\n",
    "\n",
    "with open('books.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "for entry in data:\n",
    "    title = entry[\"title\"]\n",
    "    description = entry[\"description\"]\n",
    "\n",
    "    ranked_images = rank_images(description, image_embeddings)\n",
    "\n",
    "    print(f\"Title: {title}\")\n",
    "    print(\"Most Similar Images:\")\n",
    "    for img, score in ranked_images:\n",
    "        print(f\"{img}: {score:.4f}\")\n",
    "    print(\"#\" * 30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence transformer comparison with [NV-Embed-v2](https://huggingface.co/spaces/mteb/leaderboard)\n",
    "\n",
    "(A really big model that isnt working rn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import json\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import gc\n",
    "from transformers import AutoModel\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AutoModel.from_pretrained(\"nvidia/NV-Embed-v2\", trust_remote_code=True).to(device)\n",
    "\n",
    "query_prefix = \"Instruct: Categorize the following book description into a genre.\\nQuery: \"\n",
    "category_prefix = \"\"\n",
    "\n",
    "MAX_LENGTH = 256\n",
    "\n",
    "def get_normalized_embeddings(texts, instruction):\n",
    "    with torch.no_grad():  # Prevents memory buildup\n",
    "        embeddings = model.encode(\n",
    "            texts, \n",
    "            instruction=instruction, \n",
    "            max_length=MAX_LENGTH\n",
    "        ).to(device)\n",
    "        return F.normalize(embeddings, p=2, dim=1)\n",
    "\n",
    "\n",
    "category_embeddings = get_normalized_embeddings(categories, category_prefix)\n",
    "def rank_categories(description, categories, category_embeddings):\n",
    "    description_embedding = get_normalized_embeddings([description], query_prefix)\n",
    "    scores = (description_embedding @ category_embeddings.T) * 100\n",
    "    scores = scores[0].tolist()\n",
    "    return sorted(zip(categories, scores), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "with open('books.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "for entry in data:\n",
    "    title = entry[\"title\"]\n",
    "    description = entry[\"description\"]\n",
    "    ranked_categories = rank_categories(description, categories, category_embeddings)\n",
    "    print(f\"Title: {title}\")\n",
    "    print(\"Categories:\")\n",
    "    for category, score in ranked_categories:\n",
    "        print(f\"{category}: {score:.2f}\")\n",
    "    print(\"#\" * 30)\n",
    "\n",
    "    #FREE MEMORY AFTER EACH BOOK\n",
    "    del ranked_categories\n",
    "    torch.cuda.empty_cache()  # Clears VRAM (for GPU)\n",
    "    gc.collect()  # Clears RAM (for CPU)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
